# -*- coding: utf-8 -*-
"""2_Facial_Keypoints_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NF2vNU9XnDbABG_bPhS9pvfRE-l5WY-8
"""

!unzip /content/training.zip -d /content/training
!unzip /content/test.zip -d /content/test

import pandas as pd
import numpy as np

training = pd.read_csv("./training.csv")
test = pd.read_csv("./test.csv")
training.fillna(method = 'ffill',inplace = True)
test.fillna(method = 'ffill',inplace = True)

training.isnull().any().value_counts()

x = training[['Image']].values
y = training[['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',
       'right_eye_center_y', 'left_eye_inner_corner_x',
       'left_eye_inner_corner_y', 'left_eye_outer_corner_x',
       'left_eye_outer_corner_y', 'right_eye_inner_corner_x',
       'right_eye_inner_corner_y', 'right_eye_outer_corner_x',
       'right_eye_outer_corner_y', 'left_eyebrow_inner_end_x',
       'left_eyebrow_inner_end_y', 'left_eyebrow_outer_end_x',
       'left_eyebrow_outer_end_y', 'right_eyebrow_inner_end_x',
       'right_eyebrow_inner_end_y', 'right_eyebrow_outer_end_x',
       'right_eyebrow_outer_end_y', 'nose_tip_x', 'nose_tip_y',
       'mouth_left_corner_x', 'mouth_left_corner_y', 'mouth_right_corner_x',
       'mouth_right_corner_y', 'mouth_center_top_lip_x',
       'mouth_center_top_lip_y', 'mouth_center_bottom_lip_x',
       'mouth_center_bottom_lip_y']].values
y = np.reshape(y,(-1,15,2))

imag = []
for i in range(0,7049):
  img = x[i][0].split(' ')
  img = np.array([0 if j == '' else int(j) for j in img])
  img = np.reshape(img,(96,96,1))
  imag.append(img)

print(imag)

imag = np.array(imag)
x = imag

imag

x.shape

print(type(y))

print(y[0])

y.shape

import cv2
import pandas as pd
import numpy as np
import tensorflow as tf

from sklearn.model_selection import train_test_split
X_train,X_validation,y_train,y_validation = train_test_split(x,y,test_size = 0.2,random_state = 42)

X_train.shape

x_placeholder = tf.placeholder(tf.float32,[None,96,96,1])
y_placeholder = tf.placeholder(tf.float32,[None,15,2])

num_points = 15
conv1 = tf.layers.conv2d(x_placeholder,32,5,activation = tf.nn.relu,padding="SAME")
conv1 = tf.layers.max_pooling2d(conv1,2,2,padding = "SAME")
conv2 = tf.layers.conv2d(conv1,64,5,activation = tf.nn.relu,padding="SAME")
conv2 = tf.layers.max_pooling2d(conv2,2,2,padding = "SAME")
conv3 = tf.layers.conv2d(conv2,32,5,activation = tf.nn.relu,padding="SAME")
conv3 = tf.layers.max_pooling2d(conv3,2,2,padding = "SAME")

fc1 = tf.contrib.layers.flatten(conv3)
fc1 = tf.layers.dense(fc1,512,activation = tf.nn.relu)
out = tf.layers.dense(fc1,num_points * 2)
out=tf.reshape(out,[-1,15,2])

batch_size = 128
def random_batch(x_train,y_train,batch_size):
  rnd_indices = np.random.randint(0,len(x_train),batch_size)
  x_batch = x_train[rnd_indices]
  y_batch = y_train[rnd_indices]
  return x_batch,y_batch

pred = out
print(tf.shape(pred))
print(tf.shape(y_placeholder))

subtract = tf.math.subtract(pred,y_placeholder)
binhphuong = tf.math.multiply(subtract,subtract)
distance = tf.math.sqrt(binhphuong[:,:,0]+binhphuong[:,:,1])

loss = tf.math.reduce_mean(distance)
optimizer = tf.train.AdamOptimizer()
training_op = optimizer.minimize(loss)

# Initializing the variables
init = tf.global_variables_initializer()

sess = tf.Session()
sess.run(init)

num_steps = 1000
n_epochs = 50
for step in range(1,num_steps+1):
  x_batch,y_batch = random_batch(X_train,y_train,batch_size)
  loss_value,_ = sess.run([loss,training_op], feed_dict = {x_placeholder:x_batch ,y_placeholder:y_batch})
  print(loss_value)
print("Optimization Finished!")

x_batch,y_batch = random_batch(X_train,y_train,2)
loss_value,predict = sess.run([loss,pred],feed_dict = {x_placeholder:x_batch , y_placeholder:y_batch})

print(predict[0])
print('==========')
print(y_batch[0])

